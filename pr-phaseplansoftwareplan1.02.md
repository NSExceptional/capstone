
# Peer Review

Deya and the Dudes

Software Development Plan

## Revision History

<table>
  <tr>
    <td>Date</td>
    <td>Version</td>
    <td>Description</td>
    <td>Author</td>
  </tr>
  <tr>
    <td>08/27/2018</td>
    <td>1.0</td>
    <td>Creation of Rough Draft</td>
    <td>Carlos Gamino</td>
  </tr>
  <tr>
    <td>08/29/2018</td>
    <td>1.1</td>
    <td>Filled in most info</td>
    <td>Carlos Gamino</td>
  </tr>
    <tr>
    <td>09/01/2018</td>
    <td>1.2</td>
    <td>Slight Edits</td>
    <td>Carlos Gamino</td>
  </tr>
</table>

# TABLE OF CONTENTS

## 1 Identification

1.1 Document overview  
1.2 Abbreviations
1.3 References  
1.3.1 Project References  
1.3.2 Standard and Regulatory References  
1.4 Purpose  
1.5 Scope  

## 2 Software Development Activities

2.1 Software development process  
2.1.1 Overview of process phases  
2.1.2 End of phases reviews  
2.1.3 Technical documentation  
2.1.4 Assumptions and Constraints  
2.1.5 Deliverables  
2.2   Software development tools  
2.2.1 Workstation  
2.2.2 Requirements management and documentation  
2.2.3 Evolution of the Software Development Plan  
2.2.4 Software Design  
2.2.5 Coding and automated tests  
2.2.6 Configuration management  
2.3 Software development rules and standards  

## 3 Development Process Phases  

3.1 Software Specifications 
3.1.1 Input data  
3.1.2 Content  
3.1.3 Output data  
3.1.4 Review and acceptance criteria  
3.2 Organizational Structure  

## 4 Management Process

4.1 Roles and Responsibilitites  
4.2 Project Estimates  
4.3 Project Plan  
4.4.1 Phase Plan  
4.4.2 Iteration Objectives  
4.4.3 Project Schedule  
4.5 Project Monitoring and Control
4.5.1 Requirements Management
4.5.2 Schedule Control
4.5.3 Quality Control
4.5.4 Reporting and Measurement
4.5.5 Configuration Management

## 5 Annexes

# 1. Identification

## 1.1 Document overview

This document contains documentation on the creation of an Peer Review LTI, which simply is going to be used by teachers to give them a native way to evaulate individuals in a group, within Canvas, Moodle, and other similar teaching websites. This document will be covering our purpose, what software we will be using, how we are planning to develop it, and managerial processes.

## 1.2 Abbreviations

LTI - Learning Tools Interoperability

## 1.3 References

http://www.imsglobal.org/activity/learning-tools-interoperability

### 1.3.1 Project References

<table>
  <tr>
    <td>#</td>
    <td>Document Identifier</td>
    <td>Document Title</td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>[R1]</td>
    <td>ID</td>
    <td>Add your documents references</td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
</table>

### 1.3.2 Standard and regulatory References

<table>
  <tr>
    <td>#</td>
    <td>Document Identifier</td>
    <td>Document Title</td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>[STD1]</td>
    <td>ID</td>
    <td>Add your documents references</td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
</table>

## 1.4 Purpose

Our Peer Review LTI will be used as a more fluid way to evualate students while they are doing a group project, because most teaching websites, Canvas, Moodle, etc., do not have a native way to give Peer Reviews that give analytics and feedback.  
The following people will be using the Peer Review LTI:  

- Teachers will be using it to recieve better feedback from students that are working on a group project.  
- TAs will use it if to give a more detailed look at individual group members answers.  
- Students will be using it to give their teachers and TAs feedback to things that are occuring in the group project.

## 1.5 Scope

This Software Development and Phase Plan describes the overall development plan to be used by the Peer Review LTI project, including deployment of the product. It also describes how we will manage our group during the semester of creating the Peer Review LTI.  The details of the individual iterations will be described in the Iteration Plans. The phase plan can be found in Section 4 (Management Process). The plans as outlined in this document are based upon the product requirements as defined in the Vision Document.

# 2. Software Development Activities

This section list and describes the software development activities of the Peer Review LTI that will be used in accordance with Canvas, Moodle, and other similiar websites.

## 2.1 Software development process

The software development process chosen for the Peer Review LTI is the MoSCoW/SCRUM programming model.

We are using this programming model because it does a great job in keeping the group focused on the aspects of the Peer Review Project which are the most important. It does this be keeping out priorities aligned by using a "Must Have", "Should Have", "Could Have", and "Won't Have this time" system for each timebox.

### 2.1.1 Overview of Process Phases

The lifecycle of the software development project in composed of:

- Software Inception,
- Software Research,
- Software Specification,
- Software Detailed Design,
- Software Coding and Unit Test,
- Software Integration,
- Software Verification Tests

### 2.1.2 End of phases reviews

The phases of the lifecycle are ended by the following reviews:

- Software Inception: Software Inception Review
- Software Research: Software Research Review
- Software Specification: Software Specification Review
- Software Detailed Design: Software Detailed Design Review
- Software Coding and Unit Test: Automated Tests Review
- Software Integration: Integration Test Review
- Software Verification Tests: Final Verification Test Review

The planning of phases and reviews is given below OR is in the project management plan.

### 2.1.3 Technical documentation

The following documentation is produced during the design phases:

- Software specification: SRS, STP,
- Software detailed conception: updated SRS, SDD, IDD, updated STP, STD
- Coding and unit tests: STR of unit tests
- Software tests phases : STR, VDD

### 2.1.4 Deliverables

The following items are delivered at the end of the process:
Software Engineering documentation:

- Vision Document
- Supplementary Specification Document
- Use Cases
- Domain Diagrams
- Database Design Diagrams
- Class Diagrams
- Sequence Diagrams
- System diagrams
- SAD architecture diagrams
- Glossary

MkDocs:

- Fully updated with Server/Software installation documentation
- Server/Software configuration documentation
- Developer notes
- Developer programming standards

User Documentation:

- User Guide
- Administration Procedures
- Installation Procedure

### 2.1.5 Assumptions and Constraints

{[A list of assumptions that this plan is based and any constraints, for example. budget, staff,
equipment, schedule, that apply to the project.]}

- This product assumes that all users have access to an operating system capable of viewing web pages and an internet connection.
- This product assumes that all users are using a Learning Tools that supports LTI extensions.
- This product assumes that Learning Tool sites do currently and will continue to support LTI extensions for the foreseeable future.
- This product assumes that users have basic knowledge of the Learning Tool provided for by their school to use the LTI extension.
- This product assumes that all users are registered users of the Learning Tool provided for by their school.
- This plan assumes that there will be no drastic change in the schedule for when the Peer Review LTI needs to be ready.
- This plan assumes that there will be no changes in group formations from this point forward.
- This plan assumes that all equipment will work as advertised.

## 2.2 Software development tools

### 2.2.1 Workstation

The Workstations used for developing the Peer Review LTI are comprised of 4 sets of dual screen windows stations that are going to be used at clients, and one station being used as the server.

### 2.2.2 Requirements management and documentation

The tools used to write and manage requirements are Jira, Confluence, and Slack.

### 2.2.3 Evolution of the Software Development Plan

The Software Development Plan will be revised prior to the start of each Iteration phase.

<table>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
  </tr>
</table>

### 2.2.4 Software Design

{Describe tools used for software design :}

- React, Node.js, Java

### 2.2.5 Coding and automated tests

{Describe tools used for coding and automated tests.

- Eclipse + list of plugins or VS2010 + list of plugins
- Purify, boundschecker...}

- Visual Studio

### 2.2.6 Configuration management

{Describe tools used for configuration management and bugs managment :

- Svn, git,
- Bugzilla, track, redmine...}

## 2.3 Software development rules and standards

{Describe here the standards and rules used for software development, like modelling (UML),
data modelling, coding rules}

# 3. Development Process Phases

## 3.1 Software Specifications

### 3.1.1 Input data

List input data : Data, risk analysis, design history...

- Students
- Teachers
- Classes
- Groups
- Group Members

### 3.1.2 Content

{The goal of this phase is to write the software requirements with the following (but not
exclusive) specifications:

- Functional requirements, performances, physical characteristics, environment conditions in which the software will run,
- Safety requirements including those about the exploitation and maintenance methods, the influence on the environment, the risks analysis,
- Ergonomics requirements, including manual operations, man-machine interactions, human factors,
- User documentation,
- Exploitation by end users.}

### 3.1.3 Output data

List output data : SRS, IRS, STP...

### 3.1.4 Review and acceptation criteria

Each phase ends with a software specifications review:

- Participants: Carlos Gamino
- Data reviewed: 09/01/2018

The results of each phase shall be verified with the following criteria:

- Requirements traceability,
- Coherence with external systems,
- Internal coherence,
- Testability,
- Feasibility of software detailed conception,
- Feasibility of exploitation and maintenance.

## 3.2 Organizational Structure

Prof. Micheal Aars will be serving as primary client representative and coach/mentor. Prof. Matthew Aars will be serving as secondary client representative. Deyanira Gomez will serve as Project Manager and liaison.

# 4. Management Process

## 4.1 Roles and Responsibilities

<table>
  <tr>
    <td>Person</td>
    <td>Rational Unified Process Role</td>
  </tr>
  <tr>
    <td>Carlos Gamino</td>
    <td>Implementer</td>
  </tr>
  <tr>
    <td></td>
    <td>Test Analyst</td>
  </tr>
  <tr>
    <td>Tanner Bennett</td>
    <td>System Analyst</td>
  </tr>
  <tr>
    <td></td>
    <td>User Interface Designer</td>
  </tr>
  <tr>
    <td>Justin Ritter</td>
    <td>Test Manager</td>
  </tr>
  <tr>
    <td></td>
    <td>Designer</td>
  </tr>
  <tr>
    <td>Deyanira Gomez</td>
    <td>Code Reviewer</td>
  </tr>
  <tr>
    <td></td>
    <td>Technical Writer</td>
  </tr>
</table>

Anyone on the project can perform Any Role activities.

## 4.2 Project Estimates

Estimated schedule for the Peer Review LTI project is going to be around a month and a half. We estimate that if will take about a month to fully complete all required use cases, although we want to add extra features so we estimate it will take another 2 weeks to implement the extra features and debug the project as a whole.

## 4.3 Project Plan

The project is going to be over a 3 month period. We will being using week long Sprints, which gives us 12 Sprints to finish the project.
The resources that we are going to be using are going to given to us by ECS Support, we will be using resources like Slack, Jira, Confluence, MkDocs, and BitBucket daily.

### 4.4.1 Phase Plan

- Work Breakdown Structure

1 Requirements Definition (Phase 1)

- 1.01 Requirements funding

  - 1.01.01 Review project request
  - 1.01.02 Establish preliminary justification
- 1.02 Define problem or opportunity
  - 1.02.01 Interview users
  - 1.02.02 Document problem from symptoms
  - 1.02.03 Define project scope
- 1.03 Analyze existing system
  - 1.03.01 Assemble documentation on existing system
  - 1.03.02 Identify data flows
  - 1.03.03 Identify external interfaces
  - 1.03.04 Identify problem domain
- 1.04 Document system requirements
  - 1.04.01 Document output information requirements
  - 1.04.02 Document interface constraints
- 1.05 Management review / Phase 2 funding
  - 1.05.01 Plan next phase
  - 1.05.02 Reevaluate development costs
  - 1.05.03 Reevaluate justification
  - 1.05.04 Obtain user requirements consensus
  - 1.05.05 Obtain technical consensus

2 Logical Design (Phase 2)

- 2.01 Identify detailed data requirements
  - 2.01.01 Identify output requirements
  - 2.01.02 Decompose output data
  - 2.01.03 Identify input requirements
  - 2.01.04 Identify sources of input
- 2.02 Develop prototype or user system view
  - 2.02.01 Design interactive screens
  - 2.02.02 Design reports
- 2.03 Design database
  - 2.03.01 Define logical data relations
  - 2.03.02 Design data structure
  - 2.03.03 Validate database design
- 2.05 Design Interfaces
  - 2.05.01 Design external data interfaces
  - 2.05.02 Design human interfaces
  - 2.05.03 Design intersystem interfaces
- 2.06 Specify all inputs and outputs
  - 2.06.01 Define data and interface relations
  - .06.02 Define data and system relations
- 2.07 Develop preliminary test and conversion procedures
  - 2.07.01 Identify test requirements
  - 2.07.02 Create test checklist
  - 2.07.03 Identify conversion requirements
  - 2.07.04 Create conversion checklist
- 2.08 Validate logical design
  - 2.08.01 Validate data relations
  - 2.08.02 Validate process relations
  - 2.08.03 Validate process logic
- 2.09 Validate against system architecture
  - 2.09.01 Compare logical design with systems architecture
  - 2.09.02 Identify possible inconsistencies
  - 2.09.03 Identify conflicting and concurrent development
  - 2.09.04 Identify recommended changes to systems architecture
  - 2.09.05 Identify recommended changes to strategic implementation plan
- 2.10 Management review / Phase 3 funding
  - 2.10.01 Plan next phase
  - 2.10.03 Reevaluate justification
  - 2.10.04 Obtain user requirements consensus
  - 2.10.05 Obtain technical consensus

3 Physical Design (Phase 3)

- 3.01 Design or specify physical database
  - 3.01.01 Review logical database design
  - 3.01.02 Determine access methods to be used
  - 3.01.03 Normalize database
  - 3.01.04 Design database architecture
  - 3.01.05 Identify reusable database structures
  - 3.01.06 Develop detailed database layout
  - 3.01.07 Develop database file, record, and schema descriptions
  - 3.01.08 Develop module calling sequences
  - 3.01.09 Update data dictionary entries
  - 3.01.10 Validate physical database design
- 3.02 Design processing structure
  - 3.02.01 Compose process structures from data decomposition
  - 3.02.02 Identify physical subsystems
  - 3.02.03 Identify physical programs
  - 3.02.05 Eliminate process redundancies
- 3.03 Design processing logic
  - 3.03.01 Design calling sequences
  - 3.03.02 Develop calculation specifications
  - 3.03.03 Design interface logic
  - 3.03.05 Design error recovery logic
- 3.04 Define procedures
  - 3.04.01 Review logical system design user interfaces
  - 3.04.02 Develop interactive data-entry procedures
  - 3.04.03 Develop screen specifications
  - 3.04.04 Design input forms
  - 3.04.05 Develop physical report specifications
  - 3.04.06 Develop user operating procedures
  - 3.04.07 Develop data processing operations run procedures
- 3.05 Refine test/conversion procedures
  - 3.05.01 Review test/conversion plans
  - 3.05.02 Update test/conversion plans
- 3.06 Validate physical design
  - 3.06.01 Validate data relations
  - 3.06.02 Validate process relations
  - 3.06.03 Validate process logic
  - 3.06.04 Validate procedures
  - 3.06.06 Validate system timing and sizing requirements
- 3.07 Validate against systems architecture
  - 3.07.01 Compare physical design with systems architecture
  - 3.07.02 Identify possible inconsistencies
  - 3.07.03 Identify conflicting / concurrent development
  - 3.07.04 Identify recommended changes to systems architecture
- 3.08 Management review / Phase 3 funding
  - 3.08.01 Plan next phase
  - 3.08.02 Reevaluate development costs
  - 3.08.03 Reevaluate justification
  - 3.08.04 Obtain user requirements consensus
  - 3.08.05 Obtain technical consensus

4 Programming and Unit Testing (Phase 4)

- 4.01 Decompose program modules
  - 4.01.01 Identify program modules
  - 4.01.02 Identify program module input and output
  - 4.01.03 Identify reusable modules
  - 4.01.04 Eliminate module redundancies
- 4.02 Develop program modules
  - 4.02.01 Develop detailed module logic
  - 4.02.02 Validate module logic
  - 4.02.03 Code module
  - 4.02.04 Develop module test data
  - 4.02.05 Develop call and called stubs
  - 4.02.06 Unit test program
- 4.03 Update test/conversion procedures
  - 4.03.01 Review test/conversion plans
  - 4.03.02 Update test/conversion plans
- 4.04 Management review / Phase 3 funding
  - 4.04.01 Plan next phase
  - 4.04.02 Reevaluate development costs
  - 4.04.03 Reevaluate justification
  - 4.04.04 Obtain user requirements consensus
  - 4.04.05 Obtain technical consensus

5 System Testing (Phase 5)

- 5.01 Finalize integrated system test plan
  - 5.01.01 Review interim test procedures
  - 5.01.02 Develop integration test procedures
  - 5.01.03 Develop integration test plan
  - 5.01.04 Assign integration test responsibilities
  - 5.01.05 Develop integration test data
  - 5.01.06 Train data processing personnel
- 5.02 Finalize user acceptance/training test plan
  - 5.02.01 Review interim test procedures
  - 5.02.02 Develop user acceptance criteria
  - 5.02.03 Develop final user acceptance test procedures
  - 5.02.04 Develop user acceptance test plan
  - 5.02.05 Assign user acceptance test responsibilities
  - 5.02.06 Develop user acceptance test data
  - 5.02.07 Train users
- 5.03 Conduct integration test
  - 5.03.01 Link programs and copy to test libraries
  - 5.03.02 Establish test files
  - 5.03.03 Execute integration test
- 5.04 Conduct user acceptance/training test
  - 5.04.01 Establish user acceptance test files
  - 5.04.02 Establish test files
  - 5.04.03 Execute user acceptance test
- 5.05 Management review / Phase 3 funding
  - 5.05.01 Plan next phase
  - 5.05.03 Reevaluate justification
  - 5.05.04 Obtain user requirements consensus
  - 5.05.05 Obtain technical consensus

- Gantt Chart

- Major Milestones
  - Working UI
  - Working Client Server Comminucation
  - Working Database
  - Working Analytics

### 4.4.2 Iteration Objectives

{[List the objectives to be accomplished for each of the iterations.]}

### 4.4.3 Project Schedule

{[Diagrams or tables showing target dates for completion of iterations and phases, release points, demos, and other milestones.]}

## 4.5 Project Monitoring and Control

### 4.5.1 Requirements Management

The requirements for this system are captured in the Vision document. Requested changes to requirements are captured in Change Requests, and are approved as part of the Configuration Management process.

### 4.5.2 Schedule Control

The project manager maintains a schedule showing the expected date of each milestone. The line items in the schedule include work packages assigned to individuals. Each individual who is assigned a work package provides a percent completion information to the project manager on a weekly basis. Changes in the schedule will be escalated to the project sponsors, who will then decide whether to alter scope in order to preserve target completion dates.

### 4.5.3 Quality Control

Defects will be recorded and tracked as Change Requests, and defect metrics will be gathered (see Reporting and Measurement below).

All deliverables are required to go through the appropriate review process, as described in the Development Case. The review is required to ensure that each deliverable is of acceptable quality, using guidelines described in the RUP for Small Projects review guidelines and checklists. Any defects found during review which are not corrected prior to releasing for integration must be captured as Change Requests so that they are not forgotten.

### 4.5.4 Reporting and Measurement

Updated schedule estimates, and metrics summary reports, will be generated at the end of each Sprint. The Minimal Set of Metrics, as described in the RUP will be gathered on a weekly basis.

These include:

- Earned value for completed tasks. This is used to re-estimate the schedule for the remainder of the project, and/or to identify need for scope changes.
- Total defects open and closed shown as a trend graph. This is used to help estimate the effort remaining to correct defects.
- Acceptance test cases passing shown as a trend graph. This is used to demonstrate progress to stakeholders.

In addition, overall costs will be monitored against the project budget.

### 4.5.5 Configuration Management

Appropriate tools will be selected which provide a database of Change Requests and a controlled versioned repository of project artifacts.

All source code, test scripts, and data files are included in baselines. Documentation related to the source code is also included in the baseline, such as design documentation. All customer deliverable artifacts are included in the final baseline of the iteration, including executables.

The Change Requests are reviewed and approved by one member of the project, the Change Control Manager role.

Full backups are performed monthly and incrementals are performed nightly.

# 5. Annexes

{[Additional material of use to the reader of the Software Development Plan Reference or include any project technical standards and plans which apply to this project. This typically includes the Development Case, plans for infrastructure, and product acceptance. It also typically includes Programming Guidelines, Design Guidelines, and other process guidelines. The text that follows is provided as an example.]
The project will follow the RUP for Small Projects process, as tailored by the project Development Case.
Other applicable process plans are listed in the references section, including Programming Guidelines.}